{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK6gj-ynpzIs",
        "outputId": "3ec69c0f-3f50-483a-ccad-b6108cedad99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (3.0.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna) (6.7.0)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna) (3.10.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.41)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna) (0.8.2)\n",
            "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.8.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (5.9.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (5.0.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (1.2.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (5.10.0)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.0)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.4.2)\n",
            "Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (0.5.1)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.4.1)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (4.1.1)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna\n",
        "import optuna\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import math\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.parameter import Parameter\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as utils\n",
        "import time\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import (TensorDataset, DataLoader, RandomSampler,\n",
        "                              SequentialSampler, SubsetRandomSampler,Dataset)\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rivq9BcsfkW"
      },
      "source": [
        "#Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kT_P5GKDqVB-"
      },
      "outputs": [],
      "source": [
        "def prepare_data(seqs):\n",
        "    max_len = 0\n",
        "    voc2ind = {voc:ind for ind,voc in enumerate(['<pad>', '<unk>', 'A', 'T', 'C', 'G','N','X'])}\n",
        "    \n",
        "    i = len(voc2ind)\n",
        "    \n",
        "    tokenized_seqs = []\n",
        "    for seq in seqs:\n",
        "        tokenized_seq = []\n",
        "        for e in seq:\n",
        "            seq = seq.upper()\n",
        "            if not e in voc2ind:\n",
        "                voc2ind[e] = i\n",
        "                i += 1\n",
        "            tokenized_seq.append(voc2ind[e])\n",
        "        tokenized_seqs.append(tokenized_seq)\n",
        "        \n",
        "    return tokenized_seqs, voc2ind\n",
        "\n",
        "def prepare_labels(labels):\n",
        "    tokenized_labels = []\n",
        "    label2token = {}\n",
        "    i = 0\n",
        "    for label in labels:\n",
        "        if not label in label2token:\n",
        "            label2token[label] = i\n",
        "            i += 1\n",
        "        tokenized_labels.append(label2token[label])\n",
        "    return tokenized_labels, label2token\n",
        "\n",
        "def pad(tokenized_seqs, voc2ind):\n",
        "    padded_seqs = []\n",
        "    max_len = 0\n",
        "    for seq in tokenized_seqs:\n",
        "        max_len = max(len(seq), max_len)\n",
        "    \n",
        "    for seq in tokenized_seqs:\n",
        "        padded_seq = seq + [voc2ind['<pad>']] * (max_len - len(seq))\n",
        "        padded_seqs.append(padded_seq)\n",
        "        \n",
        "    return np.array(padded_seqs, dtype=np.float32)\n",
        "\n",
        "def data_loader(train_inputs, val_inputs, train_labels, val_labels,\n",
        "                batch_size=128):\n",
        "    train_inputs, val_inputs, train_labels, val_labels =\\\n",
        "    tuple(torch.tensor(data) for data in\n",
        "          [train_inputs, val_inputs, train_labels, val_labels])\n",
        "\n",
        "    train_data = TensorDataset(train_inputs, train_labels)\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "    val_data = TensorDataset(val_inputs, val_labels)\n",
        "    val_sampler = SequentialSampler(val_data)\n",
        "    val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "    return train_dataloader, val_dataloader\n",
        "\n",
        "def preprocess(filenames, test_size = 0.2):\n",
        "  df = pd.read_excel(filenames)\n",
        "  df = df[df.columns.drop(list(df.filter(regex='1')))]\n",
        "  df.set_axis([*df.columns[:-1], 'Class'], axis=1, inplace=True)\n",
        "  df = df[['GenBarcode','Class']]\n",
        "  df.rename(columns={'GenBarcode':'Gene'},inplace=True)\n",
        "  df = df.drop(df[df.Class == 'Missing'].index)\n",
        "  df = df.drop(df[df.Class == 'Undetermined'].index)\n",
        "  df.dropna(inplace=True)\n",
        "  seqs = df.Gene.values\n",
        "  labels = df.Class.values\n",
        "\n",
        "  tokenized_seqs, voc2ind = prepare_data(seqs)\n",
        "  tokenized_seqs = pad(tokenized_seqs, voc2ind)\n",
        "\n",
        "  tokenized_labels, label2token = prepare_labels(labels)\n",
        "\n",
        "  train_inputs, test_inputs, train_labels, test_labels = train_test_split(\n",
        "      tokenized_seqs, tokenized_labels, test_size=test_size, random_state=42, stratify=tokenized_labels)\n",
        "  train_dataloader, test_dataloader = data_loader(train_inputs, test_inputs, \n",
        "                                                  train_labels, test_labels, \n",
        "                                                  batch_size=64)\n",
        "  return tokenized_seqs, voc2ind, tokenized_labels, train_dataloader, test_dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5-Fnnu0sHrm"
      },
      "source": [
        "#Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msrWfd09Jsq8"
      },
      "outputs": [],
      "source": [
        "class BiLSTM(nn.Module):\n",
        "  \n",
        "    def __init__(self, vocab_size,input_dim, hidden_dim, num_layers, output_dim):\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.feature_size = input_dim\n",
        "        self.encoder = nn.Embedding(self.vocab_size, self.feature_size)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, bidirectional = True)\n",
        "        self.fc = nn.Linear(2*hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = torch.tensor(x).to(torch.int64)\n",
        "        x = self.encoder(x)\n",
        "        h0 = torch.zeros(self.num_layers*2, x.size(0),self.hidden_dim).requires_grad_()\n",
        "        c0 = torch.zeros(self.num_layers*2, x.size(0),self.hidden_dim).requires_grad_()\n",
        "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
        "        out = torch.sigmoid(self.fc(out))\n",
        "        out = out[:, -1]\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoOsePFtsB4L"
      },
      "source": [
        "#Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S413VRA4UBSu"
      },
      "outputs": [],
      "source": [
        "def build_model(params):\n",
        "  model = BiLSTM(vocab_size = len(voc2ind), input_dim=feature, hidden_dim=params['hidden'], output_dim=1, num_layers=params['lstm'])\n",
        "  return model\n",
        "\n",
        "def train_model(params, model):\n",
        "  num_epochs = 100\n",
        "  criterion = torch.nn.BCELoss(reduction='mean')\n",
        "  hist = np.zeros(num_epochs)\n",
        "  optimizer = getattr(optim, params['optimizer'])(model.parameters(), lr=0.001)\n",
        "  for t in range(num_epochs):\n",
        "    for j,(x_train,y_train) in enumerate(train_dataloader):\n",
        "      output = model(x_train)\n",
        "      y_train = y_train.unsqueeze(1)\n",
        "      y_train = y_train.float()\n",
        "      loss = criterion(output,y_train)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    hist[t] = loss.item()\n",
        "    min_loss = hist.min()\n",
        "  return min_loss\n",
        "\n",
        "def objective(trial):\n",
        "     params = {\n",
        "              'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"]),\n",
        "              'lstm': trial.suggest_int(\"lstm\", 1, 3, 1),\n",
        "              'hidden': trial.suggest_int(\"hidden\",8, 32, 8)\n",
        "              }\n",
        "    \n",
        "     model = build_model(params)\n",
        "    \n",
        "     loss = train_model(params, model)\n",
        "\n",
        "     return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Dm_weZhgc_n",
        "outputId": "4520b296-9b92-4178-d090-2bdcb22ebf6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-10-09 03:34:24,303]\u001b[0m A new study created in memory with name: no-name-cac4dfa7-5458-43ba-a0df-5d7ffbc7d6e0\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n",
            "\u001b[32m[I 2022-10-09 03:51:06,803]\u001b[0m Trial 0 finished with value: 0.06998824328184128 and parameters: {'optimizer': 'SGD', 'lstm': 2, 'hidden': 8}. Best is trial 0 with value: 0.06998824328184128.\u001b[0m\n",
            "\u001b[32m[I 2022-10-09 04:17:03,017]\u001b[0m Trial 1 finished with value: 0.0014208841603249311 and parameters: {'optimizer': 'Adam', 'lstm': 3, 'hidden': 16}. Best is trial 1 with value: 0.0014208841603249311.\u001b[0m\n",
            "\u001b[32m[I 2022-10-09 04:28:17,348]\u001b[0m Trial 2 finished with value: 0.005149521864950657 and parameters: {'optimizer': 'RMSprop', 'lstm': 1, 'hidden': 16}. Best is trial 1 with value: 0.0014208841603249311.\u001b[0m\n",
            "\u001b[32m[I 2022-10-09 04:37:13,998]\u001b[0m Trial 3 finished with value: 0.007728338707238436 and parameters: {'optimizer': 'RMSprop', 'lstm': 1, 'hidden': 8}. Best is trial 1 with value: 0.0014208841603249311.\u001b[0m\n",
            "\u001b[32m[I 2022-10-09 05:01:51,854]\u001b[0m Trial 4 finished with value: 3.4504981158534065e-05 and parameters: {'optimizer': 'Adam', 'lstm': 2, 'hidden': 32}. Best is trial 4 with value: 3.4504981158534065e-05.\u001b[0m\n",
            "\u001b[32m[I 2022-10-09 05:18:09,548]\u001b[0m Trial 5 finished with value: 0.005749517120420933 and parameters: {'optimizer': 'RMSprop', 'lstm': 2, 'hidden': 8}. Best is trial 4 with value: 3.4504981158534065e-05.\u001b[0m\n",
            "\u001b[32m[I 2022-10-09 05:43:38,968]\u001b[0m Trial 6 finished with value: 0.05571577325463295 and parameters: {'optimizer': 'SGD', 'lstm': 3, 'hidden': 16}. Best is trial 4 with value: 3.4504981158534065e-05.\u001b[0m\n",
            "\u001b[32m[I 2022-10-09 06:07:56,964]\u001b[0m Trial 7 finished with value: 0.056969646364450455 and parameters: {'optimizer': 'SGD', 'lstm': 2, 'hidden': 32}. Best is trial 4 with value: 3.4504981158534065e-05.\u001b[0m\n",
            "\u001b[32m[I 2022-10-09 06:25:44,508]\u001b[0m Trial 8 finished with value: 0.0034777645487338305 and parameters: {'optimizer': 'Adam', 'lstm': 2, 'hidden': 16}. Best is trial 4 with value: 3.4504981158534065e-05.\u001b[0m\n",
            "\u001b[32m[I 2022-10-09 06:43:18,601]\u001b[0m Trial 9 finished with value: 0.056783903390169144 and parameters: {'optimizer': 'SGD', 'lstm': 2, 'hidden': 16}. Best is trial 4 with value: 3.4504981158534065e-05.\u001b[0m\n",
            "\u001b[32m[I 2022-10-09 07:19:43,593]\u001b[0m Trial 10 finished with value: 7.563798862975091e-05 and parameters: {'optimizer': 'Adam', 'lstm': 3, 'hidden': 32}. Best is trial 4 with value: 3.4504981158534065e-05.\u001b[0m\n",
            "\u001b[32m[I 2022-10-09 07:44:28,615]\u001b[0m Trial 11 finished with value: 4.8677924496587366e-05 and parameters: {'optimizer': 'RMSprop', 'lstm': 2, 'hidden': 32}. Best is trial 4 with value: 3.4504981158534065e-05.\u001b[0m\n",
            "\u001b[32m[I 2022-10-09 07:53:18,349]\u001b[0m Trial 12 finished with value: 0.03970460593700409 and parameters: {'optimizer': 'SGD', 'lstm': 1, 'hidden': 8}. Best is trial 4 with value: 3.4504981158534065e-05.\u001b[0m\n",
            "\u001b[32m[I 2022-10-09 08:29:45,065]\u001b[0m Trial 13 finished with value: 0.04765833541750908 and parameters: {'optimizer': 'SGD', 'lstm': 3, 'hidden': 32}. Best is trial 4 with value: 3.4504981158534065e-05.\u001b[0m\n",
            "\u001b[32m[I 2022-10-09 08:52:38,220]\u001b[0m Trial 14 finished with value: 0.05621939152479172 and parameters: {'optimizer': 'SGD', 'lstm': 3, 'hidden': 8}. Best is trial 4 with value: 3.4504981158534065e-05.\u001b[0m\n",
            "\u001b[32m[I 2022-10-09 09:15:49,730]\u001b[0m Trial 15 finished with value: 0.0019380094017833471 and parameters: {'optimizer': 'RMSprop', 'lstm': 3, 'hidden': 8}. Best is trial 4 with value: 3.4504981158534065e-05.\u001b[0m\n",
            "\u001b[32m[I 2022-10-09 09:29:18,702]\u001b[0m Trial 16 finished with value: 0.027643918991088867 and parameters: {'optimizer': 'SGD', 'lstm': 1, 'hidden': 32}. Best is trial 4 with value: 3.4504981158534065e-05.\u001b[0m\n",
            "\u001b[32m[I 2022-10-09 09:43:02,786]\u001b[0m Trial 17 finished with value: 0.0015641169156879187 and parameters: {'optimizer': 'Adam', 'lstm': 1, 'hidden': 32}. Best is trial 4 with value: 3.4504981158534065e-05.\u001b[0m\n",
            "\u001b[32m[I 2022-10-09 10:00:57,309]\u001b[0m Trial 18 finished with value: 0.0007774742553010583 and parameters: {'optimizer': 'RMSprop', 'lstm': 2, 'hidden': 16}. Best is trial 4 with value: 3.4504981158534065e-05.\u001b[0m\n",
            "\u001b[32m[I 2022-10-09 10:26:57,181]\u001b[0m Trial 19 finished with value: 0.002631637267768383 and parameters: {'optimizer': 'RMSprop', 'lstm': 3, 'hidden': 16}. Best is trial 4 with value: 3.4504981158534065e-05.\u001b[0m\n",
            "\u001b[32m[I 2022-10-09 10:50:06,568]\u001b[0m Trial 20 finished with value: 0.0047428905963897705 and parameters: {'optimizer': 'Adam', 'lstm': 3, 'hidden': 8}. Best is trial 4 with value: 3.4504981158534065e-05.\u001b[0m\n",
            "\u001b[32m[I 2022-10-09 11:06:36,562]\u001b[0m Trial 21 finished with value: 0.008586558513343334 and parameters: {'optimizer': 'Adam', 'lstm': 2, 'hidden': 8}. Best is trial 4 with value: 3.4504981158534065e-05.\u001b[0m\n",
            "\u001b[32m[I 2022-10-09 11:15:42,652]\u001b[0m Trial 22 finished with value: 0.009200548753142357 and parameters: {'optimizer': 'Adam', 'lstm': 1, 'hidden': 8}. Best is trial 4 with value: 3.4504981158534065e-05.\u001b[0m\n",
            "\u001b[32m[I 2022-10-09 11:25:43,645]\u001b[0m Trial 23 finished with value: 0.03413381054997444 and parameters: {'optimizer': 'SGD', 'lstm': 1, 'hidden': 16}. Best is trial 4 with value: 3.4504981158534065e-05.\u001b[0m\n",
            "\u001b[32m[I 2022-10-09 12:02:04,958]\u001b[0m Trial 24 finished with value: 0.00017295456200372428 and parameters: {'optimizer': 'RMSprop', 'lstm': 3, 'hidden': 32}. Best is trial 4 with value: 3.4504981158534065e-05.\u001b[0m\n",
            "\u001b[32m[I 2022-10-09 12:15:42,460]\u001b[0m Trial 25 finished with value: 0.0009127246448770165 and parameters: {'optimizer': 'RMSprop', 'lstm': 1, 'hidden': 32}. Best is trial 4 with value: 3.4504981158534065e-05.\u001b[0m\n",
            "\u001b[32m[I 2022-10-09 12:25:46,678]\u001b[0m Trial 26 finished with value: 0.010367298498749733 and parameters: {'optimizer': 'Adam', 'lstm': 1, 'hidden': 16}. Best is trial 4 with value: 3.4504981158534065e-05.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "tokenized_seqs, voc2ind, tokenized_labels, train_dataloader, test_dataloader = preprocess('pf_drug_pyrim.xlsx')\n",
        "feature = tokenized_seqs.shape[1]\n",
        "num_epochs = 100\n",
        "params = {\n",
        "              'optimizer': [\"Adam\", \"RMSprop\", \"SGD\"],\n",
        "              'lstm': [1,2,3],\n",
        "              'hidden': [8,16,32]\n",
        "              }\n",
        "study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.GridSampler(params))\n",
        "study.optimize(objective, n_trials=27)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ThkiJk-rzU-M",
        "outputId": "7e18044f-75de-49b7-c382-90a705127b10"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   params_lstm params_optimizer  params_hidden     value\n",
              "0            1             Adam              8  0.009201\n",
              "1            1             Adam             16  0.010367\n",
              "2            1             Adam             32  0.001564\n",
              "3            1          RMSprop              8  0.007728\n",
              "4            1          RMSprop             16  0.005150"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0fadb200-cc02-4943-8368-81a8f1658cf7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>params_lstm</th>\n",
              "      <th>params_optimizer</th>\n",
              "      <th>params_hidden</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Adam</td>\n",
              "      <td>8</td>\n",
              "      <td>0.009201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Adam</td>\n",
              "      <td>16</td>\n",
              "      <td>0.010367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Adam</td>\n",
              "      <td>32</td>\n",
              "      <td>0.001564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>RMSprop</td>\n",
              "      <td>8</td>\n",
              "      <td>0.007728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>RMSprop</td>\n",
              "      <td>16</td>\n",
              "      <td>0.005150</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fadb200-cc02-4943-8368-81a8f1658cf7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0fadb200-cc02-4943-8368-81a8f1658cf7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0fadb200-cc02-4943-8368-81a8f1658cf7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "hyperparameter_tuning = study.trials_dataframe()\n",
        "hyperparameter_tuning = hyperparameter_tuning[['params_lstm','params_optimizer','params_hidden','value']]\n",
        "hyperparameter_tuning = hyperparameter_tuning.sort_values(by=['params_lstm','params_optimizer','params_hidden']).reset_index()\n",
        "hyperparameter_tuning.drop('index',axis=1,inplace=True)\n",
        "hyperparameter_tuning.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCjSr64Q019k"
      },
      "outputs": [],
      "source": [
        "hyperparameter_tuning.to_excel('Hyperparameter Tuning.xlsx')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ZoOsePFtsB4L",
        "4EtRZF0ZsODn"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}